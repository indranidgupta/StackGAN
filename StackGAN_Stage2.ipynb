{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CExHqE9M1j3v",
        "outputId": "b33e59db-c47e-475f-ceee-52a04b1ea663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports section\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/StackGAN/Modules')\n",
        "\n",
        "import stackgan_stage1 as stg1\n",
        "import generate_dataset as gd # Self made dataset pipelining module\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "import cv2"
      ],
      "metadata": {
        "id": "F2poy6c812aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c76c79-df99-4b9d-f410-bcbdb6ae8134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1024)]               0         []                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  262400    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 128)                  0         ['leaky_re_lu[0][0]']         \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 228)                  0         ['lambda[0][0]',              \n",
            "                                                                     'input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 16384)                3751936   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16384)                0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 4, 4, 1024)           0         ['leaky_re_lu_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 4, 4, 1024)           4096      ['reshape[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 512)            4719104   ['batch_normalization[0][0]'] \n",
            " anspose)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 8, 8, 512)            2048      ['conv2d_transpose[0][0]']    \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu (TFOpLambda)     (None, 8, 8, 512)            0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 256)          1179904   ['tf.nn.relu[0][0]']          \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 256)          1024      ['conv2d_transpose_1[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_1 (TFOpLambda)   (None, 16, 16, 256)          0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 128)          295040    ['tf.nn.relu_1[0][0]']        \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 32, 32, 128)          512       ['conv2d_transpose_2[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_2 (TFOpLambda)   (None, 32, 32, 128)          0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2D  (None, 64, 64, 64)           73792     ['tf.nn.relu_2[0][0]']        \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 64, 64, 64)           256       ['conv2d_transpose_3[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " tf.nn.relu_3 (TFOpLambda)   (None, 64, 64, 64)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 64, 64, 3)            1731      ['tf.nn.relu_3[0][0]']        \n",
            " Transpose)                                                                                       \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)   (None, 64, 64, 3)            0         ['conv2d_transpose_4[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10291843 (39.26 MB)\n",
            "Trainable params: 10287875 (39.25 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)           3072      ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 64)           0         ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)          131072    ['leaky_re_lu_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 16, 16, 128)          512       ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)          0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 256)            524288    ['leaky_re_lu_3[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 8, 8, 256)            1024      ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 256)            0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 512)            2097152   ['leaky_re_lu_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 4, 4, 512)            2048      ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 512)            0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 4, 4, 128)]          0         []                            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 4, 4, 640)            0         ['leaky_re_lu_5[0][0]',       \n",
            " )                                                                   'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 4, 4, 512)            327680    ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 4, 4, 512)            2048      ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 4, 4, 512)            0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 8192)                 0         ['leaky_re_lu_6[0][0]']       \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    8193      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1)                    0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3097089 (11.81 MB)\n",
            "Trainable params: 3094273 (11.80 MB)\n",
            "Non-trainable params: 2816 (11.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 1024)]               0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " model (Functional)          (None, 64, 64, 3)            1029184   ['input_5[0][0]',             \n",
            "                                                          3          'input_6[0][0]']             \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)        [(None, 4, 4, 128)]          0         []                            \n",
            "                                                                                                  \n",
            " model_1 (Functional)        (None, 1)                    3097089   ['model[0][0]',               \n",
            "                                                                     'input_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13388932 (51.07 MB)\n",
            "Trainable params: 10287875 (39.25 MB)\n",
            "Non-trainable params: 3101057 (11.83 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conditional Augmentation**"
      ],
      "metadata": {
        "id": "3W-PGA-G23dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the conditional augmentation function\n",
        "def conditional_augmentation(x):\n",
        "  mean=x[:, :128]\n",
        "  log_sigma=x[:, 128:]\n",
        "  stddev = tf.exp(log_sigma)\n",
        "  epsilon = tf.random.normal(tf.shape(mean), dtype=tf.float32)\n",
        "  c = mean + stddev * epsilon\n",
        "  return c\n",
        "\n",
        "# Build the Conditional Augmentation Network (CAN) model\n",
        "def build_ca_network(input_shape=(1024,), latent_dim=256):\n",
        "  input_layer = tf.keras.layers.Input(shape=input_shape)\n",
        "  x = tf.keras.layers.Dense(latent_dim)(input_layer)\n",
        "  x = tf.keras.layers.LeakyReLU(x)\n",
        "  ca = tf.keras.layers.Lambda(conditional_augmentation)(x)\n",
        "\n",
        "  # Compiling the model\n",
        "  model = tf.keras.models.Model(inputs=input_layer, outputs=ca)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\n",
        "\n",
        "  return model\n",
        "\n",
        "# Build an embedding compressor to 128 for Char_CNN_RNN\n",
        "def embedding_compressor():\n",
        "  input=tf.keras.layers.Input(shape=(1024,))\n",
        "  compressed=tf.keras.layers.Dense(units=128)(input)\n",
        "  compressed=tf.keras.layers.LeakyReLU(alpha=0.01)(compressed)\n",
        "\n",
        "  model=tf.keras.Model(inputs=[input], outputs=[compressed])\n",
        "  return model"
      ],
      "metadata": {
        "id": "XIzLQnV12oQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kullback Liebler Divergence Loss**"
      ],
      "metadata": {
        "id": "2eW8QdoK27dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KL Divergence is used as a regularization and latent space control parameter\n",
        "def KL_adversarial_loss(y_true, y_pred):\n",
        "  mean=y_pred[:, :128]\n",
        "  logsigma=y_pred[:, 128:]\n",
        "  return K.mean(-logsigma+0.5*(-1+K.exp(2.0*logsigma)+K.square(mean)))"
      ],
      "metadata": {
        "id": "eKE1GqGO2x22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miscellaneous Functions**"
      ],
      "metadata": {
        "id": "9ldyB87O3CoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image, filename, img_path):\n",
        "  # Saves image at specified file path\n",
        "  if os.path.exists(img_path)==False:\n",
        "    os.makedirs(img_path)\n",
        "  cv2.imwrite((img_path+filename), image)\n",
        "\n",
        "\n",
        "# Build an embedding compressor to 128 for Char_CNN_RNN\n",
        "def embedding_compressor():\n",
        "  input=tf.keras.layers.Input(shape=(1024,))\n",
        "  compressed=tf.keras.layers.Dense(units=128)(input)\n",
        "  compressed=tf.keras.layers.LeakyReLU(alpha=0.01)(compressed)\n",
        "\n",
        "  model=tf.keras.Model(inputs=[input], outputs=[compressed])\n",
        "  return model"
      ],
      "metadata": {
        "id": "BB8nBKk922SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 2 Generator**"
      ],
      "metadata": {
        "id": "Xo7vH-Lu3QRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Residual Block\n",
        "def residualGen(input):\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False, kernel_initializer='he_uniform')(input)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(3,3), padding='same', use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "\n",
        "  x = tf.keras.layers.add([x, input])\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "def Stage2_Generator():\n",
        "  input_embedding = tf.keras.Input(shape=(1024,))\n",
        "  input_images = tf.keras.Input(shape=(64, 64, 3))\n",
        "  # Conditioning Augmentation\n",
        "  ca = tf.keras.layers.Dense(256)(input_embedding)\n",
        "  ca = tf.keras.layers.LeakyReLU(alpha=0.2)(ca)\n",
        "  c = tf.keras.layers.Lambda(conditional_augmentation)(ca)\n",
        "  # Downsampling\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(1,1))(input_images)\n",
        "  x = tf.keras.layers.Conv2D(128, kernel_size=(3,3), strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
        "  x = tf.keras.layers.Conv2D(256, kernel_size=(4,4), strides=2, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(1,1))(x)\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(4,4), strides=2, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  # Concatenate text conditioning block with the encoded image\n",
        "  concat = concat_custom(c, x)\n",
        "  # Residual Blocks\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(1,1))(concat)\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(3,3), use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  x = residualGen(x)\n",
        "  x = residualGen(x)\n",
        "  x = residualGen(x)\n",
        "  x = residualGen(x)\n",
        "  # Upsampling\n",
        "  x = UpSample2(x, 512)\n",
        "  x = UpSample2(x, 256)\n",
        "  x = UpSample2(x, 128)\n",
        "  x = UpSample2(x, 64)\n",
        "  x = tf.keras.layers.Conv2D(3, kernel_size=(3,3), padding='same', use_bias=False, kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.Activation('tanh')(x)\n",
        "  stage2_gen = tf.keras.Model(inputs=[input_embedding, input_images], outputs=[x])\n",
        "  return stage2_gen\n",
        "\n",
        "# Upsample block\n",
        "def UpSample2(x,num_kernels):\n",
        "  x = tf.keras.layers.UpSampling2D(size=(2,2))(x)\n",
        "  x = tf.keras.layers.Conv2D(num_kernels, kernel_size=(3,3), padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(gamma_initializer='ones', beta_initializer='zeros')(x)\n",
        "  x = tf.keras.layers.ReLU()(x)\n",
        "  return x\n",
        "\n",
        "def concat_custom(c,x): #concatenate text conditioning block with the image\n",
        "  c = K.expand_dims(c, axis=1)\n",
        "  c = K.expand_dims(c, axis=1)\n",
        "  c = K.tile(c, [1, 16, 16, 1])\n",
        "  return K.concatenate([c, x], axis = 3)"
      ],
      "metadata": {
        "id": "hGRBQ6KLJy25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Stage2_Generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "aFkTa76KJ709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6710c232-a4d3-41f5-e1a5-a68b51552c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)        [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPaddin  (None, 66, 66, 3)            0         ['input_9[0][0]']             \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 128)          3456      ['zero_padding2d[0][0]']      \n",
            "                                                                                                  \n",
            " re_lu (ReLU)                (None, 64, 64, 128)          0         ['conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadd  (None, 66, 66, 128)          0         ['re_lu[0][0]']               \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 1024)]               0         []                            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 256)          524288    ['zero_padding2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  262400    ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 32, 32, 256)          1024      ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 256)                  0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_1 (ReLU)              (None, 32, 32, 256)          0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 128)                  0         ['leaky_re_lu_7[0][0]']       \n",
            "                                                                                                  \n",
            " zero_padding2d_2 (ZeroPadd  (None, 34, 34, 256)          0         ['re_lu_1[0][0]']             \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda  (None, 1, 128)               0         ['lambda_1[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 16, 16, 512)          2097152   ['zero_padding2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLamb  (None, 1, 1, 128)            0         ['tf.expand_dims[0][0]']      \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 16, 16, 512)          2048      ['conv2d_7[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " tf.tile (TFOpLambda)        (None, 16, 16, 128)          0         ['tf.expand_dims_1[0][0]']    \n",
            "                                                                                                  \n",
            " re_lu_2 (ReLU)              (None, 16, 16, 512)          0         ['batch_normalization_10[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)      (None, 16, 16, 640)          0         ['tf.tile[0][0]',             \n",
            "                                                                     're_lu_2[0][0]']             \n",
            "                                                                                                  \n",
            " zero_padding2d_3 (ZeroPadd  (None, 18, 18, 640)          0         ['tf.concat[0][0]']           \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 512)          2949120   ['zero_padding2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 16, 16, 512)          2048      ['conv2d_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_3 (ReLU)              (None, 16, 16, 512)          0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 512)          2359296   ['re_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 16, 16, 512)          2048      ['conv2d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_4 (ReLU)              (None, 16, 16, 512)          0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_4[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 16, 16, 512)          2048      ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 16, 16, 512)          0         ['batch_normalization_13[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_3[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_5 (ReLU)              (None, 16, 16, 512)          0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 16, 16, 512)          2048      ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_6 (ReLU)              (None, 16, 16, 512)          0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 16, 16, 512)          2048      ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 16, 16, 512)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_5[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_7 (ReLU)              (None, 16, 16, 512)          0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_7[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 16, 16, 512)          2048      ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_8 (ReLU)              (None, 16, 16, 512)          0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_8[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 16, 16, 512)          2048      ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 16, 16, 512)          0         ['batch_normalization_17[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_7[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_9 (ReLU)              (None, 16, 16, 512)          0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 16, 16, 512)          2048      ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_10 (ReLU)             (None, 16, 16, 512)          0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 512)          2359296   ['re_lu_10[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 16, 16, 512)          2048      ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 16, 16, 512)          0         ['batch_normalization_19[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     're_lu_9[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_11 (ReLU)             (None, 16, 16, 512)          0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 32, 32, 512)          0         ['re_lu_11[0][0]']            \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 32, 32, 512)          2359296   ['up_sampling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 32, 32, 512)          2048      ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_12 (ReLU)             (None, 32, 32, 512)          0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 64, 64, 512)          0         ['re_lu_12[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 64, 64, 256)          1179648   ['up_sampling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 64, 64, 256)          1024      ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_13 (ReLU)             (None, 64, 64, 256)          0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['re_lu_13[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 128, 128, 128)        294912    ['up_sampling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 128, 128, 128)        512       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_14 (ReLU)             (None, 128, 128, 128)        0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 256, 256, 128)        0         ['re_lu_14[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 256, 256, 64)         73728     ['up_sampling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 256, 256, 64)         256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " re_lu_15 (ReLU)             (None, 256, 256, 64)         0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 256, 256, 3)          1728      ['re_lu_15[0][0]']            \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 256, 256, 3)          0         ['conv2d_21[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28645440 (109.27 MB)\n",
            "Trainable params: 28632768 (109.23 MB)\n",
            "Non-trainable params: 12672 (49.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 2 Discriminator**"
      ],
      "metadata": {
        "id": "zSDly6ZE3TPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Stage 2 Discriminator\n",
        "def Stage2_Discriminator():\n",
        "  # Input image\n",
        "  input1 = tf.keras.Input(shape=(256, 256, 3))\n",
        "  x = tf.keras.layers.Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeUniform())(input1)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "  # Downsampling and convoluting image\n",
        "  x = downSample(x, 128)\n",
        "  x = downSample(x, 256)\n",
        "  x = downSample(x, 512)\n",
        "  x = downSample(x, 1024)\n",
        "  x = downSample(x, 2048)\n",
        "  x = downSample(x, 1024, (1,1), 1)\n",
        "  x = downSample(x, 512, (1,1), 1, False)\n",
        "  x = disResidualBlock(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  # Concatenating compressing text embedding to generated distribution\n",
        "  input2 = tf.keras.Input(shape=(4,4,128,)) # Text embedding\n",
        "  x = tf.keras.layers.concatenate([x, input2])\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  # Logit generation\n",
        "  x= tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform())(x) # 0 or 1\n",
        "  x = tf.keras.layers.Activation('tanh')(x)\n",
        "  # Model\n",
        "  stage2_dis = tf.keras.Model(inputs=[input1, input2], outputs=[x])\n",
        "  return stage2_dis\n",
        "\n",
        "# Downsampling block for Discriminator\n",
        "def downSample(x, kernels, kernel_size=(4,4), strides=2, activation=True):\n",
        "  x = tf.keras.layers.Conv2D(kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  if activation:\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "  return x\n",
        "\n",
        "# Discriminator residual block\n",
        "def disResidualBlock(x):\n",
        "  xd = downSample(x, 128, (1,1), 1)\n",
        "  xd = downSample(x, 128, (3,3), 1)\n",
        "  xd = downSample(x, 512, (3,3), 1, False)\n",
        "  return tf.keras.layers.add([x,xd])"
      ],
      "metadata": {
        "id": "EiiuTJfv3Xml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator=Stage2_Discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bymD-SPD3jiy",
        "outputId": "df910ef5-e49e-4505-a5ac-dcf2596ac822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 64)         3072      ['input_10[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 128, 128, 64)         0         ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 64, 64, 128)          131072    ['leaky_re_lu_8[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 64, 64, 128)          512       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 64, 64, 128)          0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 32, 32, 256)          524288    ['leaky_re_lu_9[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 32, 32, 256)          1024      ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 32, 32, 256)          0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 16, 16, 512)          2097152   ['leaky_re_lu_10[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 16, 16, 512)          2048      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 16, 16, 512)          0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 8, 8, 1024)           8388608   ['leaky_re_lu_11[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 8, 8, 1024)           4096      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 8, 8, 1024)           0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 4, 4, 2048)           3355443   ['leaky_re_lu_12[0][0]']      \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 4, 4, 2048)           8192      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 4, 4, 2048)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 4, 4, 1024)           2097152   ['leaky_re_lu_13[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 4, 4, 1024)           4096      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 4, 4, 1024)           0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 4, 4, 512)            524288    ['leaky_re_lu_14[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 4, 4, 512)            2048      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 4, 4, 512)            2359296   ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 4, 4, 512)            2048      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 4, 4, 512)            0         ['batch_normalization_30[0][0]\n",
            "                                                                    ',                            \n",
            "                                                                     'batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 4, 4, 512)            0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 4, 4, 128)]          0         []                            \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 4, 4, 640)            0         ['leaky_re_lu_17[0][0]',      \n",
            " )                                                                   'input_11[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 4, 4, 512)            327680    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 4, 4, 512)            2048      ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 4, 4, 512)            0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 8192)                 0         ['leaky_re_lu_18[0][0]']      \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    8193      ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 1)                    0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 50041345 (190.89 MB)\n",
            "Trainable params: 50028289 (190.84 MB)\n",
            "Non-trainable params: 13056 (51.00 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 2 Adversarial Model**"
      ],
      "metadata": {
        "id": "p6XZQTBk3kK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Stage 2 Adversarial model\n",
        "def Stage2_Adversarial(generator_model, discriminator_model):\n",
        "    input1 = tf.keras.Input(shape=(1024,)) # Text embedding\n",
        "    input2 = tf.keras.Input(shape=(64, 64, 3,)) # Gen1 image\n",
        "    input3 = tf.keras.Input(shape=(4, 4, 128,)) # Compressed embedding\n",
        "\n",
        "    img = generator_model([input1, input2]) # Text, Gen1 image\n",
        "  # Discriminator not trainable during adversarial game\n",
        "    discriminator_model.trainable = False\n",
        "  # Model\n",
        "    discrimOutput = discriminator_model([img, input3])\n",
        "    adversarial_model = tf.keras.Model(inputs=[input1, input2, input3], outputs=[discrimOutput])\n",
        "    return adversarial_model"
      ],
      "metadata": {
        "id": "MsLRVZwA3oQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial=Stage2_Adversarial(generator, discriminator)\n",
        "adversarial.summary()"
      ],
      "metadata": {
        "id": "YZEfz5mX3r-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee647a2-303b-44ba-ab72-a8a1a8d6cdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 1024)]               0         []                            \n",
            "                                                                                                  \n",
            " input_13 (InputLayer)       [(None, 64, 64, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " model_3 (Functional)        (None, 256, 256, 3)          2864544   ['input_12[0][0]',            \n",
            "                                                          0          'input_13[0][0]']            \n",
            "                                                                                                  \n",
            " input_14 (InputLayer)       [(None, 4, 4, 128)]          0         []                            \n",
            "                                                                                                  \n",
            " model_4 (Functional)        (None, 1)                    5004134   ['model_3[0][0]',             \n",
            "                                                          5          'input_14[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 78686785 (300.17 MB)\n",
            "Trainable params: 28632768 (109.23 MB)\n",
            "Non-trainable params: 50054017 (190.94 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Stage2_GAN:\n",
        "  def __init__(self, train_ds, epochs=400, z_dim=100, batch_size=64, gen_lr=0.001, dis_lr=0.001):\n",
        "    self.epochs=epochs\n",
        "    self.z_dim=z_dim\n",
        "    self.batch_size=batch_size\n",
        "    self.gen_lr=gen_lr\n",
        "    self.dis_lr=dis_lr\n",
        "    self.img_size=256\n",
        "    # Training dataset\n",
        "    self.train_ds=train_ds\n",
        "\n",
        "    # Optimizers to the models\n",
        "    self.gen_optimizer=tf.keras.optimizers.Adam(beta_1=0.6, beta_2=0.999, learning_rate=self.gen_lr)\n",
        "    self.dis_optimizer=tf.keras.optimizers.Adam(beta_1=0.6, beta_2=0.999, learning_rate=self.dis_lr)\n",
        "\n",
        "    # Models\n",
        "    self.generator=Stage2_Generator()\n",
        "    self.generator.compile(optimizer=self.gen_optimizer, loss='binary_crossentropy')\n",
        "    self.discriminator=Stage2_Discriminator()\n",
        "    self.discriminator.loss_function=tf.nn.sigmoid_cross_entropy_with_logits\n",
        "    self.discriminator.compile(optimizer=self.dis_optimizer, loss=self.discriminator.loss_function)\n",
        "    self.stage1_generator=stg1.Stage1_Generator()\n",
        "    self.stage1_generator.trainable=False\n",
        "    self.stage1_generator.load_weights('/content/drive/MyDrive/StackGAN/Stage_1/Model_weights/Gen_Epochs:All.h5')\n",
        "\n",
        "    # Embedding Compressor\n",
        "    self.embed_compressor=embedding_compressor()\n",
        "    self.embed_compressor.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\n",
        "\n",
        "    # Adversarial Model\n",
        "    self.model=Stage2_Adversarial(self.generator, self.discriminator)\n",
        "    self.model.compile(loss=['binary_crossentropy', KL_adversarial_loss], loss_weights=[1., 2.], optimizer=self.gen_optimizer)\n",
        "\n",
        "    self.checkpoint2 = tf.train.Checkpoint(gen_optimizer=self.gen_optimizer, discriminator_optimizer=self.dis_optimizer, generator=self.generator,discriminator=self.discriminator)\n",
        "\n",
        "  def train_GAN(self):\n",
        "    self.gen_loss_log=[]\n",
        "    self.dis_loss_log=[]\n",
        "    start=time.time()\n",
        "    for i in range(self.epochs):\n",
        "      gen_epoch_loss=[]\n",
        "      dis_epoch_loss=[]\n",
        "      print(\"<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\")\n",
        "      print(\"<><><><><><><><> Started Epoch:\",(i+1),\"<><><><><><><><><><><><><><><><><><><>\")\n",
        "\n",
        "      # Current batch from dataset\n",
        "      real_img, real_embed=next(self.train_ds)\n",
        "      if((i+1)%75==0):\n",
        "        K.set_value(self.gen_optimizer.learning_rate, self.gen_optimizer.learning_rate/2)\n",
        "        K.set_value(self.dis_optimizer.learning_rate, self.dis_optimizer.learning_rate/2)\n",
        "\n",
        "      # Iterating through mini-batches\n",
        "      num_iters=125\n",
        "      for iter in range(num_iters):\n",
        "        if((iter+1)%5==0):\n",
        "          print(\":3 \", end='')\n",
        "\n",
        "        # To train discriminator on real images-real captions\n",
        "        if(iter!=0):\n",
        "          real_img, real_embed=next(self.train_ds)\n",
        "        real_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = .9, maxval = 1.)\n",
        "\n",
        "        # To train discriminator on real images-mismatched real captions\n",
        "        mismatched_img=tf.roll(real_img, shift=1, axis=0)\n",
        "        mismatched_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = .9, maxval = 1.)\n",
        "\n",
        "        # To train discriminator on fake images-real captions\n",
        "        low_fake_img=self.stage1_generator([real_embed, tf.random.normal(shape=(self.batch_size, self.z_dim), stddev=0.2)])\n",
        "        fake_img=self.generator([real_embed, low_fake_img])\n",
        "        fake_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = 0., maxval = .1)\n",
        "\n",
        "        # Real captions compressed and reshaped for discriminator\n",
        "        compressed_embed=self.embed_compressor.predict_on_batch(real_embed)\n",
        "        compressed_embed=tf.reshape(compressed_embed, (-1, 1, 1, 128))\n",
        "        compressed_embed=tf.tile(compressed_embed, (1, 4, 4, 1))\n",
        "\n",
        "        self.discriminator.trainable=True\n",
        "        # Train Discriminator manually\n",
        "        with tf.GradientTape() as dis_tape:\n",
        "          # Discriminator logits\n",
        "          real_logits=self.discriminator(inputs=[real_img, compressed_embed])\n",
        "          fake_logits=self.discriminator(inputs=[fake_img, compressed_embed])\n",
        "          mismatched_logits=self.discriminator(inputs=[mismatched_img, compressed_embed])\n",
        "\n",
        "          # Loss for each logit\n",
        "          loss_real=tf.reduce_mean(self.discriminator.loss_function(real_labels, real_logits))\n",
        "          loss_fake=tf.reduce_mean(self.discriminator.loss_function(fake_labels, fake_logits))\n",
        "          loss_mismatched=tf.reduce_mean(self.discriminator.loss_function(mismatched_labels, mismatched_logits))\n",
        "\n",
        "          # Total discriminator weighted loss\n",
        "          dis_loss=tf.reduce_mean(0.5*tf.add(loss_real, 0.5*tf.add(loss_fake, loss_mismatched)))\n",
        "\n",
        "        # Discriminator gradient descent on optimizer\n",
        "        discriminator_gradient=dis_tape.gradient(dis_loss, self.discriminator.trainable_variables)\n",
        "        print(discriminator_gradient[-1])\n",
        "        self.dis_optimizer.apply_gradients(zip(discriminator_gradient, self.discriminator.trainable_variables))\n",
        "        dis_epoch_loss.append([\"Batch:\",(iter+1),\"|| Loss:\", dis_loss])\n",
        "        self.discriminator.trainable=False\n",
        "\n",
        "        # Training Adversarial GAN model\n",
        "        gen_loss=self.model.train_on_batch([real_embed, low_fake_img, compressed_embed], [real_labels])\n",
        "        gen_epoch_loss.append([\"Batch:\",(iter+1),\"|| Loss:\", gen_loss])\n",
        "\n",
        "      print(\"\\nDiscriminator's Loss after epoch number\",i,\"is=\",dis_loss)\n",
        "      print(\"Generator's Loss after epoch number\",i,\"is=\",gen_loss)\n",
        "\n",
        "      # Saving 20 generator images after every 50 epochs\n",
        "      if(i%50==0):\n",
        "        gen_images=self.generator.predict_on_batch([real_embed, tf.random.normal(shape=(self.batch_size, self.z_dim), stddev=0.2)])\n",
        "        for num, image in enumerate(gen_images[:10]):\n",
        "          image=127.5*image+127.5\n",
        "          save_image(image, f'{i+1}_{num}.jpg', '/content/drive/MyDrive/StackGAN/Stage_2/Generated_Images/')\n",
        "\n",
        "      # Saving model weights after every 50 epochs\n",
        "      if(i%50==0):\n",
        "        self.generator.save_weights(f'/content/drive/MyDrive/StackGAN/Stage_2/Model_weights/Gen_Epochs:{i+1}.h5')\n",
        "        self.discriminator.save_weights(f'/content/drive/MyDrive/StackGAN/Stage_2/Model_weights/Dis_Epochs:{i+1}.h5')\n",
        "\n",
        "      # Appending losses\n",
        "      self.gen_loss_log.append(gen_epoch_loss)\n",
        "      self.dis_loss_log.append(dis_epoch_loss)\n",
        "\n",
        "      print(\"<><><><><><><><> Time elapsed:\",(time.time()-start),\"<><><><><><><><><><><>\")\n",
        "      print(\"<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\")\n",
        "\n",
        "    with open('/content/drive/MyDrive/StackGAN/Stage_2/Model_weights/Loss.txt', 'w') as file:\n",
        "      # Writing Generator Loss Log file\n",
        "      file.write('Generator Loss:\\n')\n",
        "      for item in self.gen_loss_log:\n",
        "        item=str(item)+'\\n'\n",
        "        file.write(item)\n",
        "\n",
        "      # Writing Discriminator Loss Log file\n",
        "      file.write('Discriminator Loss:\\n')\n",
        "      for item in self.dis_loss_log:\n",
        "        item=str(item)+'\\n'\n",
        "        file.write(item)\n",
        "\n",
        "    self.generator.save_weights('/content/drive/MyDrive/StackGAN/Stage_2/Model_weights/Gen_Epochs:All.h5')\n",
        "    self.discriminator.save_weights('/content/drive/MyDrive/StackGAN/Stage_2/Model_weights/Dis_Epochs:All.h5')"
      ],
      "metadata": {
        "id": "PycCyWEr31L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Stage 2 GAN**"
      ],
      "metadata": {
        "id": "FS233-ytCD2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=time.time()\n",
        "\n",
        "# Getting the train dataset\n",
        "dataset=gd.Dataset_Generator(img_size=(256, 256))\n",
        "train=dataset.get_train_dataset()\n",
        "\n",
        "# Iterator is passed to the model for training\n",
        "train_iterator=iter(train)"
      ],
      "metadata": {
        "id": "rFR5jfjYBzo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 2 GAN model\n",
        "Stage_2_GAN=Stage2_GAN(train_iterator)\n",
        "# Training the model\n",
        "Stage_2_GAN.train_GAN()\n",
        "\n",
        "print(\"Total time elapsed in training:\", (time.time()-start_time))"
      ],
      "metadata": {
        "id": "bQ8jqQ_IB2dI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc98b3a1-c719-4426-95d1-81a85ce025e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "<><><><><><><><> Started Epoch: 1 <><><><><><><><><><><><><><><><><><><>\n",
            "tf.Tensor([-0.07821339], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "XBZ72kDdBzn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}