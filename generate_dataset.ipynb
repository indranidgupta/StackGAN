{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0wK2h7gCLii",
        "outputId": "31c9937d-4e7c-4fb0-91af-e45fa826a156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports section\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import cv2\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Qtm8oLsZDHcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of parallel processing units for dataset reading\n",
        "units=tf.data.experimental.AUTOTUNE\n",
        "\n",
        "class Dataset_Generator():\n",
        "  def __init__(self, img_size, batch_size=64):\n",
        "    # Pathnames\n",
        "    dir=\"/content/drive/My Drive/StackGAN/Dataset/CUB_200_2011\"\n",
        "    train_dir=dir+\"/train\"\n",
        "    test_dir=dir+\"/test\"\n",
        "    train_embedpaths=train_dir+\"/char-CNN-RNN-embeddings.pickle\"\n",
        "    test_embedpaths=test_dir+\"/char-CNN-RNN-embeddings.pickle\"\n",
        "    train_filepaths=train_dir+\"/filenames.pickle\"\n",
        "    test_filepaths=test_dir+\"/filenames.pickle\"\n",
        "    bboxes_paths=dir+\"/bounding_boxes.txt\"\n",
        "    image_paths =dir+\"/images.txt\"\n",
        "    images=dir+\"/images\"\n",
        "\n",
        "    # Image dimensions and batch sizes\n",
        "    self.img_h=img_size[0]\n",
        "    self.img_w=img_size[1]\n",
        "    self.batch_size=batch_size\n",
        "\n",
        "    # Generate train image filenames\n",
        "    with open(train_filepaths, 'rb') as f:\n",
        "      self.train_filenames=pickle.load(f, encoding='latin1')\n",
        "      self.train_filenames=[os.path.join(images, fname)+'.jpg' for fname in self.train_filenames]\n",
        "\n",
        "    # Generate test image filenames\n",
        "    with open(test_filepaths, 'rb') as f:\n",
        "      self.test_filenames=pickle.load(f, encoding='latin1')\n",
        "      self.test_filenames=[os.path.join(images, fname)+'.jpg' for fname in self.test_filenames]\n",
        "\n",
        "    # Generate train Char-CNN-RNN embedding filenames\n",
        "    with open(train_embedpaths, 'rb') as f:\n",
        "      self.train_embeds=pickle.load(f, encoding='latin1')\n",
        "\n",
        "    # Generate test Char-CNN-RNN embedding filenames\n",
        "    with open(test_embedpaths, 'rb') as f:\n",
        "      self.test_embeds=pickle.load(f, encoding='latin1')\n",
        "\n",
        "    # Generate bounding boxes within a dictionary, reading them from the file\n",
        "    bounding_boxes={}\n",
        "    with open(bboxes_paths, 'rb') as f:\n",
        "      coords=f.read()\n",
        "      coords=coords.splitlines()\n",
        "      coords=[coord.decode('utf-8') for coord in coords]\n",
        "      for i in range(len(coords)):\n",
        "        bounding_box=coords[i].split()\n",
        "        bounding_boxes[bounding_box[0]]=[int(float(c)) for c in coords[i].split()][1:]\n",
        "\n",
        "    # Generate image filenames within a dictionary, read from the file\n",
        "    image_fnames={}\n",
        "    with open(image_paths, 'rb') as f:\n",
        "      im_fs=f.read()\n",
        "      im_fs=im_fs.splitlines()\n",
        "      im_fs=[im_f.decode('utf-8') for im_f in im_fs]\n",
        "      for i in range(len(im_fs)):\n",
        "        im_f=im_fs[i].split()\n",
        "        image_fnames[im_f[0]]=im_f[1]\n",
        "\n",
        "    # Mapping generated bounding boxes with their corresponding images\n",
        "    bboxes_map={}\n",
        "    for im_f in bounding_boxes.keys():\n",
        "      bboxes_map[images+'/'+image_fnames[im_f]]=bounding_boxes[im_f]\n",
        "    # Generate train bounding boxes\n",
        "    self.train_bboxes=[]\n",
        "    for i in range(len(self.train_filenames)):\n",
        "      self.train_bboxes.append(bboxes_map[self.train_filenames[i]])\n",
        "\n",
        "    # Generate test bounding boxes\n",
        "    self.test_bboxes=[]\n",
        "    for i in range(len(self.test_filenames)):\n",
        "      self.test_bboxes.append(bboxes_map[self.test_filenames[i]])\n",
        "\n",
        "  # Crop images to bounding boxes\n",
        "  def crop(self, image, box):\n",
        "    image=image.numpy()\n",
        "    if box is not None:\n",
        "      x, y, w, h=box # Unpack to get bounding box co-ordinates\n",
        "      image=image[y:(y+h), x:(x+w)]\n",
        "      image=cv2.resize(image, (self.img_w, self.img_h))\n",
        "    return image\n",
        "\n",
        "  # Read image from the dataset\n",
        "  def read_image(self, path, embeds, box):\n",
        "    image=tf.io.read_file(path)\n",
        "    image=tf.image.decode_jpeg(image, channels=3)\n",
        "    image=tf.py_function(func=self.crop, inp=[image, box], Tout=tf.float32)\n",
        "    image.set_shape([self.img_w, self.img_h, 3])\n",
        "    # Normalizing values reduces dataset parse duration\n",
        "    image=(image-127.5)/127.5 # Normalizing image pixel values down\n",
        "    embed_no=np.random.randint(0, embeds.shape[0]-1)\n",
        "    embed=embeds[embed_no]\n",
        "    return image, embed\n",
        "\n",
        "  # Get training dataset\n",
        "  def get_train_dataset(self):\n",
        "    size=len(self.train_filenames)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((self.train_filenames, self.train_embeds, self.train_bboxes))\n",
        "    dataset=dataset.shuffle(size)\n",
        "    dataset=dataset.repeat()\n",
        "    dataset=dataset.map(self.read_image, num_parallel_calls=units)\n",
        "    dataset=dataset.batch(self.batch_size, drop_remainder=True)\n",
        "    dataset=dataset.prefetch(1)\n",
        "    return dataset\n",
        "\n",
        "  # Get testing dataset\n",
        "  def get_test_dataset(self):\n",
        "    size=len(self.train_filenames)\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((self.test_filenames, self.test_embeds, self.test_bboxes))\n",
        "    dataset=dataset.shuffle(size)\n",
        "    dataset=dataset.repeat()\n",
        "    dataset=dataset.map(self.read_image, num_parallel_calls=units)\n",
        "    dataset=dataset.batch(self.batch_size, drop_remainder=True)\n",
        "    dataset=dataset.prefetch(1)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "0yQJtYrfxJxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "dataset=Dataset_Generator(img_size=(64, 64))\n",
        "train=dataset.get_train_dataset()\n",
        "test=dataset.get_test_dataset()\n",
        "print(\"Time elapsed:\",time.time()-start,\"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xKA4QhZ2dUI",
        "outputId": "570d08ac-91fa-4f27-9259-0fce6aefcf88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed: 44.00000715255737 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_iter=iter(train)\n",
        "img_batch, _=next(batch_iter)"
      ],
      "metadata": {
        "id": "S58mNr03zqTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2lRyms3DB1aF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}