{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u_ULRBS9kna",
        "outputId": "95599f23-ef19-4b8e-d5ce-14769c798e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports section\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/StackGAN/Modules')\n",
        "\n",
        "import generate_dataset as gd # Self made dataset pipelining module\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import cv2\n",
        "import time"
      ],
      "metadata": {
        "id": "oVq5JwY89pVY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miscellaneous Functions**"
      ],
      "metadata": {
        "id": "eBofUyjsdssM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image, filename, img_path):\n",
        "  # Saves image at specified file path\n",
        "  if os.path.exists(img_path)==False:\n",
        "    os.makedirs(img_path)\n",
        "  image=image.numpy().astype('uint8')\n",
        "  cv2.imwrite((img_path+filename), image)"
      ],
      "metadata": {
        "id": "JQizoV4SdsIQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kulback Liebler Loss for Generator**"
      ],
      "metadata": {
        "id": "XSkYZwbsDRAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KL Divergence is used as a regularization and latent space control parameter\n",
        "def KL_adversarial_loss(y_true, y_pred):\n",
        "  mean=y_pred[:, :128]\n",
        "  logsigma=y_pred[:, 128:]\n",
        "  return K.mean(-logsigma+0.5*(-1+K.exp(2.0*logsigma)+K.square(mean)))"
      ],
      "metadata": {
        "id": "4PtJLJfaBB-C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conditional Augmentation**"
      ],
      "metadata": {
        "id": "-qg6-vhHDMBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the conditional augmentation function\n",
        "def conditional_augmentation(x):\n",
        "  mean=x[:, :128]\n",
        "  log_sigma=x[:, 128:]\n",
        "  stddev = tf.exp(log_sigma)\n",
        "  epsilon = tf.random.normal(tf.shape(mean), dtype=tf.float32)\n",
        "  c = mean + stddev * epsilon\n",
        "  return c\n",
        "\n",
        "# Build the Conditional Augmentation Network (CAN) model\n",
        "def build_ca_network(input_shape=(1024,), latent_dim=256):\n",
        "  input_layer = tf.keras.layers.Input(shape=input_shape)\n",
        "  x = tf.keras.layers.Dense(latent_dim)(input_layer)\n",
        "  x = tf.keras.layers.LeakyReLU(x)\n",
        "  ca = tf.keras.layers.Lambda(conditional_augmentation)(x)\n",
        "\n",
        "  # Compiling the model\n",
        "  model = tf.keras.models.Model(inputs=input_layer, outputs=ca)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\n",
        "\n",
        "  return model\n",
        "\n",
        "# Build an embedding compressor to 128 for Char_CNN_RNN\n",
        "def embedding_compressor():\n",
        "  input=tf.keras.layers.Input(shape=(1024,))\n",
        "  compressed=tf.keras.layers.Dense(units=128)(input)\n",
        "  compressed=tf.keras.layers.LeakyReLU(alpha=0.01)(compressed)\n",
        "\n",
        "  model=tf.keras.Model(inputs=[input], outputs=[compressed])\n",
        "  return model"
      ],
      "metadata": {
        "id": "UiOQ7lkeCvCM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 1 Generator Model**"
      ],
      "metadata": {
        "id": "13Y4__FTH-z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsampling block for generator\n",
        "def upSample(x,dim):\n",
        "  x=tf.keras.layers.Conv2DTranspose(dim, kernel_size=3, strides=(2, 2), padding=\"same\", kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "  x=tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99)(x)\n",
        "  x=tf.nn.relu(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "# Stage 1 Generator builder\n",
        "def Stage1_Generator():\n",
        "  # Conditional Augmentation of  embedding vector\n",
        "  inp=tf.keras.Input(shape=(1024,))\n",
        "  ca=tf.keras.layers.Dense(256)(inp)\n",
        "  ca=tf.keras.layers.LeakyReLU(alpha=0.01)(ca)\n",
        "  c=tf.keras.layers.Lambda(conditional_augmentation)(ca)\n",
        "\n",
        "  # Latent space conditioning\n",
        "  noise=tf.keras.Input(shape=(100,))\n",
        "  gen_input=tf.keras.layers.Concatenate(axis = 1)([c,noise])\n",
        "  x=tf.keras.layers.Dense(units = 128*8*4*4, kernel_initializer = tf.keras.initializers.HeUniform())(gen_input)\n",
        "  x=tf.keras.layers.LeakyReLU(alpha=0.01)(x)\n",
        "  x=tf.keras.layers.Reshape(target_shape = (4, 4, 128*8), input_shape = (128*8*4*4, ))(x)\n",
        "  x=tf.keras.layers.BatchNormalization(axis = -1, momentum = 0.99)(x)\n",
        "\n",
        "  # Upsampling and deconvoluting latent space\n",
        "  x=upSample(x,512)\n",
        "  x=upSample(x,256)\n",
        "  x=upSample(x,128)\n",
        "  x=upSample(x,64)\n",
        "  x=tf.keras.layers.Conv2DTranspose(3,kernel_size=3,strides=1,padding=\"same\",kernel_initializer=tf.keras.initializers.GlorotUniform())(x)\n",
        "  x=tf.nn.tanh(x)\n",
        "  # Model\n",
        "  stack1_gen=tf.keras.Model(inputs=[inp,noise], outputs=[x])\n",
        "  return stack1_gen"
      ],
      "metadata": {
        "id": "oG5oFvJaG9Gt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=Stage1_Generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzXh3P8OSP4c",
        "outputId": "d9321993-acc8-4629-913c-c7c30a29f5f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          262400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 128)          0           ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 228)          0           ['lambda[0][0]',                 \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 16384)        3751936     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 16384)        0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 4, 4, 1024)   0           ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4, 4, 1024)  4096        ['reshape[0][0]']                \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 8, 8, 512)   4719104     ['batch_normalization[0][0]']    \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 8, 8, 512)   2048        ['conv2d_transpose[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu (TFOpLambda)        (None, 8, 8, 512)    0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 256)  1179904    ['tf.nn.relu[0][0]']             \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_transpose_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu_1 (TFOpLambda)      (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 128)  295040     ['tf.nn.relu_1[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_transpose_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu_2 (TFOpLambda)      (None, 32, 32, 128)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 64)  73792       ['tf.nn.relu_2[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_transpose_3[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu_3 (TFOpLambda)      (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, 64, 64, 3)   1731        ['tf.nn.relu_3[0][0]']           \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.tanh (TFOpLambda)      (None, 64, 64, 3)    0           ['conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,291,843\n",
            "Trainable params: 10,287,875\n",
            "Non-trainable params: 3,968\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 1 Discriminator**"
      ],
      "metadata": {
        "id": "LO8eSwZVMnjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Stage 1 Discriminator\n",
        "def Stage1_Discriminator():\n",
        "  # Input image\n",
        "  input1 = tf.keras.Input(shape=(64, 64, 3))\n",
        "  x = tf.keras.layers.Conv2D(64, kernel_size=(4,4), strides=2, padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.HeUniform())(input1)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "  # Downsampling and convoluting image\n",
        "  x = downSample(x, 128)\n",
        "  x = downSample(x, 256)\n",
        "  x = downSample(x, 512)\n",
        "\n",
        "  # Concatenating compressing text embedding to generated distribution\n",
        "  input2 = tf.keras.Input(shape=(4,4,128,)) # Text embedding\n",
        "  x = tf.keras.layers.concatenate([x, input2])\n",
        "  x = tf.keras.layers.Conv2D(512, kernel_size=(1,1), padding='same', strides=1, use_bias=False,kernel_initializer='he_uniform')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  # Logit generation\n",
        "  x= tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.GlorotUniform())(x) # 0 or 1\n",
        "  x = tf.keras.layers.Activation('sigmoid')(x)\n",
        "  # Model\n",
        "  stage1_dis = tf.keras.Model(inputs=[input1, input2], outputs=[x])\n",
        "  return stage1_dis\n",
        "\n",
        "# Downsampling block for Discriminator\n",
        "def downSample(x, kernels, kernel_size=(4,4), strides=2, activation=True):\n",
        "  x = tf.keras.layers.Conv2D(kernels, kernel_size=kernel_size, padding='same', strides=strides, use_bias=False, kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "  if activation:\n",
        "    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "3TVpWYS6MrmU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator=Stage1_Discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuW4Llk2UHh2",
        "outputId": "a033a980-91e1-4367-a949-48b34b6e0b94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 64)   3072        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 32, 32, 64)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 4, 4, 512)    2097152     ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 4, 4, 640)    0           ['leaky_re_lu_5[0][0]',          \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 4, 4, 512)    327680      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 4, 4, 512)    0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            8193        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1)            0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,097,089\n",
            "Trainable params: 3,094,273\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 1 Adversarial Model**"
      ],
      "metadata": {
        "id": "S7hPj2lZM9QP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Stage 1 Adversarial model\n",
        "def Stage1_Adversarial(generator_model, discriminator_model):\n",
        "    input1 = tf.keras.Input(shape=(1024,)) # Text embedding\n",
        "    input2 = tf.keras.Input(shape=(100,)) # Noise\n",
        "    input3 = tf.keras.Input(shape=(4,4,128,)) # Compressed embedding\n",
        "\n",
        "    img = generator_model([input1, input2]) # Text, noise\n",
        "\n",
        "  # Discriminator not trainable during adversarial game\n",
        "    discriminator_model.trainable = False\n",
        "\n",
        "  # Model\n",
        "    discrimOutput = discriminator_model([img, input3])\n",
        "    adversarial_model = tf.keras.Model(inputs=[input1, input2, input3], outputs=[discrimOutput])\n",
        "    return adversarial_model"
      ],
      "metadata": {
        "id": "AiBngrx2NATv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial=Stage1_Adversarial(generator, discriminator)\n",
        "adversarial.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my93mwj_WQ9R",
        "outputId": "b53c9787-eedc-4c63-ed2d-7d9f06ad1191"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             (None, 64, 64, 3)    10291843    ['input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None, 4, 4, 128)]  0           []                               \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, 1)            3097089     ['model[0][0]',                  \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,388,932\n",
            "Trainable params: 10,287,875\n",
            "Non-trainable params: 3,101,057\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 1 Model**"
      ],
      "metadata": {
        "id": "uaQaCmsHQEUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.version_utils import disallow_legacy_graph\n",
        "class Stage1_GAN:\n",
        "  def __init__(self, train_ds, epochs=350, z_dim=100, batch_size=64, gen_lr=0.001, dis_lr=0.001):\n",
        "    self.epochs=epochs\n",
        "    self.z_dim=z_dim\n",
        "    self.batch_size=batch_size\n",
        "    self.gen_lr=gen_lr\n",
        "    self.dis_lr=dis_lr\n",
        "    self.img_size=64\n",
        "    # Training dataset\n",
        "    self.train_ds=train_ds\n",
        "\n",
        "    # Optimizers to the models\n",
        "    self.gen_optimizer=tf.keras.optimizers.Adam(beta_1=0.6, beta_2=0.999, learning_rate=self.gen_lr)\n",
        "    self.dis_optimizer=tf.keras.optimizers.Adam(beta_1=0.6, beta_2=0.999, learning_rate=self.dis_lr)\n",
        "\n",
        "    # Models\n",
        "    self.generator=Stage1_Generator()\n",
        "    self.generator.compile(optimizer=self.gen_optimizer, loss='mse')\n",
        "    self.discriminator=Stage1_Discriminator()\n",
        "    self.discriminator.loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.discriminator.compile(optimizer=self.dis_optimizer, loss=self.discriminator.loss_function)\n",
        "\n",
        "    # Embedding Compressor\n",
        "    self.embed_compressor=embedding_compressor()\n",
        "    self.embed_compressor.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')\n",
        "\n",
        "    # Adversarial Model\n",
        "    self.model=Stage1_Adversarial(self.generator, self.discriminator)\n",
        "    self.model.compile(loss=['binary_crossentropy', KL_adversarial_loss], loss_weights=[1., 2.], optimizer=self.gen_optimizer)\n",
        "\n",
        "    self.checkpoint1 = tf.train.Checkpoint(gen_optimizer=self.gen_optimizer, discriminator_optimizer=self.dis_optimizer, generator=self.generator,discriminator=self.discriminator)\n",
        "\n",
        "  def train_GAN(self):\n",
        "    self.gen_loss_log=[]\n",
        "    self.dis_loss_log=[]\n",
        "    start=time.time()\n",
        "    for i in range(self.epochs):\n",
        "      gen_epoch_loss=[]\n",
        "      dis_epoch_loss=[]\n",
        "      print(\"<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\")\n",
        "      print(\"<><><><><><><><> Started Epoch:\",(i+1),\"<><><><><><><><><><><><><><><><><><><>\")\n",
        "\n",
        "      # Current batch from dataset\n",
        "      real_img, real_embed=next(self.train_ds)\n",
        "      if((i+1)%75==0):\n",
        "        K.set_value(self.gen_optimizer.learning_rate, self.gen_optimizer.learning_rate/2)\n",
        "        K.set_value(self.dis_optimizer.learning_rate, self.dis_optimizer.learning_rate/2)\n",
        "      # Iterating through mini-batches\n",
        "      num_iters=125\n",
        "      for iter in range(num_iters):\n",
        "        if((iter+1)%5==0):\n",
        "          print(\":3 \", end='')\n",
        "\n",
        "        # To train discriminator on real images-real captions\n",
        "        if(iter!=0):\n",
        "          real_img, real_embed=next(self.train_ds)\n",
        "        real_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = .9, maxval = 1.)\n",
        "\n",
        "        # To train discriminator on real images-mismatched real captions\n",
        "        mismatched_img=tf.roll(real_img, shift=1, axis=0)\n",
        "        mismatched_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = .9, maxval = 1.)\n",
        "\n",
        "        # To train discriminator on fake images-real captions\n",
        "        fake_img=self.generator.predict_on_batch([real_embed, np.random.normal(0, 1, size=(self.batch_size, self.z_dim))])\n",
        "        fake_labels= tf.random.uniform(shape=(self.batch_size, 1), minval = 0., maxval = .1)\n",
        "\n",
        "        # Real captions compressed and reshaped for discriminator\n",
        "        compressed_embed=self.embed_compressor.predict_on_batch(real_embed)\n",
        "        compressed_embed=tf.reshape(compressed_embed, (-1, 1, 1, 128))\n",
        "        compressed_embed=tf.tile(compressed_embed, (1, 4, 4, 1))\n",
        "\n",
        "        # Discriminator logits\n",
        "        real_logits=self.discriminator.predict_on_batch([real_img, compressed_embed])\n",
        "        fake_logits=self.discriminator.predict_on_batch([fake_img, compressed_embed])\n",
        "        mismatched_logits=self.discriminator.predict_on_batch([mismatched_img, compressed_embed])\n",
        "\n",
        "        # Loss for each logit\n",
        "        loss_real=tf.reduce_mean(self.discriminator.loss_function(real_labels, real_logits))\n",
        "        loss_fake=tf.reduce_mean(self.discriminator.loss_function(fake_labels, fake_logits))\n",
        "        loss_mismatched=tf.reduce_mean(self.discriminator.loss_function(mismatched_labels, mismatched_logits))\n",
        "\n",
        "        # Train Discriminator manually\n",
        "        with tf.GradientTape() as dis_tape:\n",
        "          # Total discriminator weighted loss\n",
        "          dis_loss=0.5*tf.add(loss_real, 0.5*tf.add(loss_fake, loss_mismatched))\n",
        "\n",
        "        # Discriminator gradient descent on optimizer\n",
        "        discriminator_gradient=dis_tape.gradient(dis_loss, self.discriminator.trainable_variables)\n",
        "        self.dis_optimizer.apply_gradients(zip(discriminator_gradient, self.discriminator.trainable_variables))\n",
        "        dis_epoch_loss.append([\"Batch:\",(iter+1),\"|| Loss:\", dis_loss])\n",
        "\n",
        "        # Training Adversarial GAN model\n",
        "        gen_loss=self.model.train_on_batch([real_embed, np.random.normal(0, 1, size=(self.batch_size, self.z_dim)), compressed_embed], [real_labels])\n",
        "        gen_epoch_loss.append([\"Batch:\",(iter+1),\"|| Loss:\", gen_loss])\n",
        "\n",
        "      print(\"Discriminator's's Loss after epoch number\",i,\"is=\",dis_loss)\n",
        "      print(\"Generator's Loss after epoch number\",i,\"is=\",gen_loss)\n",
        "\n",
        "      # Saving 20 generator images after every 50 epochs\n",
        "      if(i%50==0):\n",
        "        gen_images=self.generator.predict_on_batch([real_embed, np.random.normal(0, 1, size=(self.batch_size, self.z_dim))])\n",
        "        for num, image in enumerate(gen_images[:10]):\n",
        "          image=127.5*image+127.5\n",
        "          image=image.numpy().astype('uint8')\n",
        "          save_image(image, f'{i+1}_{num}.jpg', '/content/drive/MyDrive/StackGAN/Stage_1/Generated_Images/')\n",
        "\n",
        "      # Saving model weights after every 50 epochs\n",
        "      if(i%50==0):\n",
        "        self.generator.save_weights(f'/content/drive/MyDrive/StackGAN/Stage_1/Model_Weights/Gen_Epochs:{i+1}.h5')\n",
        "        self.discriminator.save_weights(f'/content/drive/MyDrive/StackGAN/Stage_1/Model_Weights/Dis_Epochs:{i+1}.h5')\n",
        "\n",
        "      # Appending losses\n",
        "      self.gen_loss_log.append(gen_epoch_loss)\n",
        "      self.dis_loss_log.append(dis_epoch_loss)\n",
        "\n",
        "      print(\"Time elapsed:\",(time.time()))\n",
        "      print(\"<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\")\n",
        "\n",
        "    with open('/content/drive/MyDrive/StackGAN/Stage_1/Model_Weights/Loss.txt', 'w') as file:\n",
        "      # Writing Generator Loss Log file\n",
        "      file.write('Generator Loss:\\n')\n",
        "      for item in self.gen_loss:\n",
        "        item=str(item)+'\\n'\n",
        "        file.write(item)\n",
        "\n",
        "      # Writing Discriminator Loss Log file\n",
        "      file.write('Discriminator Loss:\\n')\n",
        "      for item in self.dis_loss:\n",
        "        item=str(item)+'\\n'\n",
        "        file.write(item)\n",
        "\n",
        "    self.generator.save_weights('/content/drive/MyDrive/StackGAN/Stage_1/Model_Weights/Gen_Epochs:All.h5')\n",
        "    self.discriminator.save_weights('/content/drive/MyDrive/StackGAN/Stage_1/Model_Weights/Gen_Epochs:All.h5')"
      ],
      "metadata": {
        "id": "_yZ0cXhCRRvK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Stage 1 GAN**"
      ],
      "metadata": {
        "id": "R8Oz0_A1jIuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=time.time()\n",
        "\n",
        "# Getting the train dataset\n",
        "dataset=gd.Dataset_Generator(img_size=(64, 64))\n",
        "train=dataset.get_train_dataset()\n",
        "\n",
        "# Iterator is passed to the model for training\n",
        "train_iterator=iter(train)"
      ],
      "metadata": {
        "id": "G4yB1kP2jSWU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stage 1 GAN model\n",
        "Stage_1_GAN=Stage1_GAN(train_iterator)\n",
        "# Training the model\n",
        "Stage_1_GAN.train_GAN()\n",
        "\n",
        "print(\"Total time elapsed in training:\", (time.time()-start_time))"
      ],
      "metadata": {
        "id": "pGmVmHZY1D9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af241e3-5fa2-4850-a6a0-fb4361bff5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "<><><><><><><><> Started Epoch: 1 <><><><><><><><><><><><><><><><><><><>\n",
            ":3 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "soP5bJZ9jyak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}